# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V6nJ_uGytFeZT_XGZ49eNJhlblvfMe-c
"""

import pandas as pd
from time import time
from sklearn import tree
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score
from sklearn import svm
from sklearn.metrics import confusion_matrix
import seaborn as sn
import keras
from keras.models import Sequential
from keras.layers import Dense

features = ["duration","protocol_type","service","flag","src_bytes",
    "dst_bytes","land","wrong_fragment","urgent","hot","num_failed_logins",
    "logged_in","num_compromised","root_shell","su_attempted","num_root",
    "num_file_creations","num_shells","num_access_files","num_outbound_cmds",
    "is_host_login","is_guest_login","count","srv_count","serror_rate",
    "srv_serror_rate","rerror_rate","srv_rerror_rate","same_srv_rate",
    "diff_srv_rate","srv_diff_host_rate","dst_host_count","dst_host_srv_count",
    "dst_host_same_srv_rate","dst_host_diff_srv_rate","dst_host_same_src_port_rate",
    "dst_host_srv_diff_host_rate","dst_host_serror_rate","dst_host_srv_serror_rate",
    "dst_host_rerror_rate","dst_host_srv_rerror_rate","label"]
data = pd.read_csv('kddcup.data.corrected', names = features, header=None)
print('The no of data points are:',data.shape[0])
print('The no of features are:',data.shape[1])
print('Some of the features are:',features[:10])

output = data['label'].values
labels = set(output)
print(labels)
print(len(labels))
print('Null values in dataset are',len(data[data.isnull().any(1)]))
data = data.dropna(how='any',axis=0) 
data.drop_duplicates(subset=features, keep='first', inplace = True)
data.shape
data.to_pickle('data.pkl')

plt.figure(figsize=(20,15))
class_distribution = data['label'].value_counts()
class_distribution.plot(kind='bar')
plt.xlabel('Class')
plt.ylabel('Data points per Class')
plt.title('Distribution of yi in train data')
plt.grid()
plt.show()
data['label']

protocol = pd.get_dummies(data.protocol_type)
protocol = protocol.astype('int') 
data = data.drop('protocol_type',axis=1)
data = pd.concat([data, protocol], axis=1)
service = pd.get_dummies(data.service)
service = service.astype('int') 
data = data.drop('service',axis=1)
data = pd.concat([data, service], axis=1)
flag = pd.get_dummies(data.flag)
flag = flag.astype('int') 
data = data.drop('flag',axis=1)
data = pd.concat([data, flag], axis=1)
print(data)

X_train, X_test, Y_train, Y_test = train_test_split(data.drop('label', axis=1), data['label'], stratify=data['label'], test_size=0.25)
print('Train data')
print(X_train.shape)
print(Y_train.shape)
print('='*20)
print('Test data')
print(X_test.shape)
print(Y_test.shape)



print(Y_train)
Y_train[Y_train != "normal."] = "attack."
Y_train[Y_train == 'normal.'] = 1
Y_train[Y_train == 'attack.'] = 0
Y_test[Y_test != "normal."] = "attack."
Y_test[Y_test == 'normal.'] = 1
Y_test[Y_test == 'attack.'] = 0
print(Y_train)
print(Y_test)

Y_train = Y_train.to_frame()
Y_train = Y_train.astype('int')
Y_test = Y_test.to_frame()
Y_test = Y_test.astype('int')
print(Y_train)

clf = LinearSVC(random_state = 0)
t0 = time()
Y_train = Y_train.squeeze()
clf.fit(X_train, Y_train)
tt = time() - t0
print ("Classifier trained in {} seconds.".format(round(tt, 3)))

t0 = time()
pred = clf.predict(X_test)
tt = time() - t0
print ("Predicted in {} seconds".format(round(tt,3)))
acc = accuracy_score(pred, Y_test)
print ("Accuracy is {}.".format(round(acc,4)))

X = data.drop('label', axis=1)
Y = data['label']

mat = confusion_matrix(Y_test, pred)
print(mat)
df_cm = pd.DataFrame(mat, range(2), range(2))
plt.figure(figsize=(10,10))
sn.set(font_scale=2) # for label size
ax = sn.heatmap(df_cm, annot=False, annot_kws={"size": 16}) # font size
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.savefig('d:\SVM.jpg')
plt.show()

gnb = GaussianNB()
gnb = gnb.fit(X_train, Y_train)
t0 = time()
y_pred = gnb.predict(X_test)
tt = time() - t0
print ("Predicted in {} seconds".format(round(tt,3)))

print(y_pred)

acc1 = accuracy_score(y_pred, Y_test)
print ("Accuracy is {}.".format(round(acc1,4)))
mat = confusion_matrix(Y_test, y_pred)
print(mat)
df_cm = pd.DataFrame(mat, range(2), range(2))
plt.figure(figsize=(10,10))
sn.set(font_scale=2) # for label size
ax = sn.heatmap(df_cm, annot=False, annot_kws={"size": 16}) # font size
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.savefig('d:\GNB.jpg')
plt.show()

dtree = tree.DecisionTreeClassifier()
dtree = dtree.fit(X_train, Y_train)
t0 = time()
y_p = dtree.predict(X_test)
tt = time() - t0
print ("Predicted in {} seconds".format(round(tt,3)))
acc2 = accuracy_score(y_p, Y_test)
print ("Accuracy is {}.".format(round(acc2,4)))

mat = confusion_matrix(Y_test, y_p)
print(mat)
df_cm = pd.DataFrame(mat, range(2), range(2))
plt.figure(figsize=(10,10))
sn.set(font_scale=2) # for label size
ax = sn.heatmap(df_cm, annot=False, annot_kws={"size": 16}) # font size
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.savefig('d:\DTree.jpg')
plt.show()

model = Sequential()
model.add(Dense(12, input_dim=7, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(15, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# fit the keras model on the dataset
model.fit(X, y, epochs=150, batch_size=10)
# evaluate the keras model
_, accuracy = model.evaluate(X, y)
print('Accuracy: %.2f' % (accuracy*100))